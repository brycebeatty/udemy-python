{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import GetOldTweets3 as old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetCriteria = old.manager.TweetCriteria().setQuerySearch('europe refugees')\\\n",
    "                                           .setSince(\"2015-05-01\")\\\n",
    "                                           .setUntil(\"2015-09-30\")\\\n",
    "                                           .setMaxTweets(1)\n",
    "tweet = old.manager.TweetManager.getTweets(tweetCriteria)[0]\n",
    "print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-da134ec4c5e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtwitterscraper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mquery_tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\bbeatty\\Anaconda3\\lib\\site-packages\\twitterscraper\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtwitterscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mquery_tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtwitterscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mquery_tweets_from_user\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtwitterscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mquery_user_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bbeatty\\Anaconda3\\lib\\site-packages\\twitterscraper\\query.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m \u001b[0mproxies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_proxies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[0mproxy_pool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproxies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bbeatty\\Anaconda3\\lib\\site-packages\\twitterscraper\\query.py\u001b[0m in \u001b[0;36mget_proxies\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'table'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'proxylisttable'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mlist_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m     \u001b[0mlist_td\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'td'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlist_tr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mlist_td\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist_td\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_all'"
     ]
    }
   ],
   "source": [
    "from twitterscraper import query_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Royals (#Royals OR #TogetherRoyal) (@Royals) since:2022-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "limits = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-d446c79b84f7>:7: FutureWarning: username is deprecated, use user.username instead\n",
      "  tweets.append([tweet.date, tweet.username, tweet.content])\n"
     ]
    }
   ],
   "source": [
    "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
    "    #print(vars(tweet))\n",
    "    #break\n",
    "    if len(tweets) == limits:\n",
    "        break\n",
    "    else:\n",
    "        tweets.append([tweet.date, tweet.username, tweet.content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(tweets, columns=['Date', 'Username', 'Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-02 04:36:08+00:00</td>\n",
       "      <td>bsimmstheboss1</td>\n",
       "      <td>@Royals are officially the worst team in the @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-01 22:28:13+00:00</td>\n",
       "      <td>SportsAviation</td>\n",
       "      <td>‚öæÔ∏è Kansas City Royals (@Royals) #TogetherRoyal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-01 22:18:38+00:00</td>\n",
       "      <td>MisMarcadores_</td>\n",
       "      <td>#MLB ‚öæÔ∏è\\n@CleGuardians 4 @Royals 0\\n#Guardians...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-01 20:42:49+00:00</td>\n",
       "      <td>SarahNauser</td>\n",
       "      <td>The @Royals are saving up their runs to win bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-01 20:41:45+00:00</td>\n",
       "      <td>Satan_Andrew</td>\n",
       "      <td>@LGRed @Royals @CleGuardians @MLB @YouTube @Si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date        Username  \\\n",
       "0 2022-06-02 04:36:08+00:00  bsimmstheboss1   \n",
       "1 2022-06-01 22:28:13+00:00  SportsAviation   \n",
       "2 2022-06-01 22:18:38+00:00  MisMarcadores_   \n",
       "3 2022-06-01 20:42:49+00:00     SarahNauser   \n",
       "4 2022-06-01 20:41:45+00:00    Satan_Andrew   \n",
       "\n",
       "                                               Tweet  \n",
       "0  @Royals are officially the worst team in the @...  \n",
       "1  ‚öæÔ∏è Kansas City Royals (@Royals) #TogetherRoyal...  \n",
       "2  #MLB ‚öæÔ∏è\\n@CleGuardians 4 @Royals 0\\n#Guardians...  \n",
       "3  The @Royals are saving up their runs to win bi...  \n",
       "4  @LGRed @Royals @CleGuardians @MLB @YouTube @Si...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2187 entries, 0 to 2186\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype              \n",
      "---  ------    --------------  -----              \n",
      " 0   Date      2187 non-null   datetime64[ns, UTC]\n",
      " 1   Username  2187 non-null   object             \n",
      " 2   Tweet     2187 non-null   object             \n",
      "dtypes: datetime64[ns, UTC](1), object(2)\n",
      "memory usage: 51.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"@brycebeatty_ today's cold @ home üòí https://weather.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@user today's cold @ home üòí http\n"
     ]
    }
   ],
   "source": [
    "tweet_words = []\n",
    "for word in tweet.split(' '):\n",
    "    if word.startswith('@') and len(word) > 1:\n",
    "        word = '@user'\n",
    "    elif word.startswith('http'):\n",
    "        word = \"http\"\n",
    "    tweet_words.append(word)\n",
    "\n",
    "tweet_proc = \" \".join(tweet_words)\n",
    "print(tweet_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 747/747 [00:00<00:00, 249kB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 476M/476M [00:35<00:00, 14.1MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 878k/878k [00:00<00:00, 3.97MB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 446k/446k [00:00<00:00, 1.81MB/s]\n",
      "Downloading: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 150/150 [00:00<00:00, 59.6kB/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(roberta)\n",
    "\n",
    "labels = ['Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceClassifierOutput(loss=None, logits=tensor([[ 1.3710,  0.3350, -1.7215]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
    "output = model(encoded_tweet['input_ids'], encoded_tweet['attention_mask'])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.3709722   0.33496124 -1.721458  ]\n"
     ]
    }
   ],
   "source": [
    "#output = model(encoded_tweet['input_ids'], encoded_tweet['attention_mask'])\n",
    "\n",
    "output = model(**encoded_tweet)\n",
    "\n",
    "scores = output[0][0].detach().numpy()\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative 0.7141535\n",
      "Neutral 0.25342983\n",
      "Positive 0.03241651\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(scores)):\n",
    "    l = labels[i]\n",
    "    s = scores[i]\n",
    "    print(l,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-77ad38bb886c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtweet_words2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tweet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'@'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'@user'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\bbeatty\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5463\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5464\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5465\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5467\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "tweet_words2 = []\n",
    "for word in df2['Tweet'].split(' '):\n",
    "    if word.startswith('@') and len(word) > 1:\n",
    "        word = '@user'\n",
    "    elif word.startswith('http'):\n",
    "        word = \"http\"\n",
    "    tweet_words2.append(word)\n",
    "\n",
    "tweet_proc2 = \" \".join(tweet_words2)\n",
    "print(tweet_proc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['tokenized_sents'] = df2.apply(lambda row: nltk.word_tokenize(row['Tweet']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>tokenized_sents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-03 15:00:01+00:00</td>\n",
       "      <td>Royals</td>\n",
       "      <td>Some of our finest plays from the month of May...</td>\n",
       "      <td>[Some, of, our, finest, plays, from, the, mont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-03 14:30:05+00:00</td>\n",
       "      <td>KUSportsMed</td>\n",
       "      <td>It's time to #BringOutTheBlue! The @Royals are...</td>\n",
       "      <td>[It, 's, time, to, #, BringOutTheBlue, !, The,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-03 13:45:04+00:00</td>\n",
       "      <td>Chefdavekc</td>\n",
       "      <td>@Royals Happy Birthday Ace 30‚öæüíô\\n#Togetherroyal</td>\n",
       "      <td>[@, Royals, Happy, Birthday, Ace, 30‚öæüíô, #, Tog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-03 12:07:54+00:00</td>\n",
       "      <td>gv116</td>\n",
       "      <td>I keep checking for news that the @royals have...</td>\n",
       "      <td>[I, keep, checking, for, news, that, the, @, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-03 11:52:00+00:00</td>\n",
       "      <td>nelson_atkins</td>\n",
       "      <td>Welcome home @Royals! Let's keep the balls in ...</td>\n",
       "      <td>[Welcome, home, @, Royals, !, Let, 's, keep, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>2022-01-04 17:34:26+00:00</td>\n",
       "      <td>jjrands</td>\n",
       "      <td>@Royals #Royals https://t.co/g6I5i7QDDw</td>\n",
       "      <td>[@, Royals, #, Royals, https, :, //t.co/g6I5i7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>2022-01-02 02:47:30+00:00</td>\n",
       "      <td>mwlarchives</td>\n",
       "      <td>2002 #MWL box score #559/990 7/1 @burlingtonbe...</td>\n",
       "      <td>[2002, #, MWL, box, score, #, 559/990, 7/1, @,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>2022-01-02 01:25:21+00:00</td>\n",
       "      <td>SlamSportsCards</td>\n",
       "      <td>Today is 1/1 - just like this @KrisBubic 2021 ...</td>\n",
       "      <td>[Today, is, 1/1, -, just, like, this, @, KrisB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2022-01-01 20:10:32+00:00</td>\n",
       "      <td>GoldenHalloFame</td>\n",
       "      <td>Who would you put on a Kansas City Baseball Mo...</td>\n",
       "      <td>[Who, would, you, put, on, a, Kansas, City, Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>2022-01-01 04:52:01+00:00</td>\n",
       "      <td>RoyalsMikester</td>\n",
       "      <td>Wishing you the best for the New Year and alwa...</td>\n",
       "      <td>[Wishing, you, the, best, for, the, New, Year,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2198 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Date         Username  \\\n",
       "0    2022-06-03 15:00:01+00:00           Royals   \n",
       "1    2022-06-03 14:30:05+00:00      KUSportsMed   \n",
       "2    2022-06-03 13:45:04+00:00       Chefdavekc   \n",
       "3    2022-06-03 12:07:54+00:00            gv116   \n",
       "4    2022-06-03 11:52:00+00:00    nelson_atkins   \n",
       "...                        ...              ...   \n",
       "2193 2022-01-04 17:34:26+00:00          jjrands   \n",
       "2194 2022-01-02 02:47:30+00:00      mwlarchives   \n",
       "2195 2022-01-02 01:25:21+00:00  SlamSportsCards   \n",
       "2196 2022-01-01 20:10:32+00:00  GoldenHalloFame   \n",
       "2197 2022-01-01 04:52:01+00:00   RoyalsMikester   \n",
       "\n",
       "                                                  Tweet  \\\n",
       "0     Some of our finest plays from the month of May...   \n",
       "1     It's time to #BringOutTheBlue! The @Royals are...   \n",
       "2       @Royals Happy Birthday Ace 30‚öæüíô\\n#Togetherroyal   \n",
       "3     I keep checking for news that the @royals have...   \n",
       "4     Welcome home @Royals! Let's keep the balls in ...   \n",
       "...                                                 ...   \n",
       "2193            @Royals #Royals https://t.co/g6I5i7QDDw   \n",
       "2194  2002 #MWL box score #559/990 7/1 @burlingtonbe...   \n",
       "2195  Today is 1/1 - just like this @KrisBubic 2021 ...   \n",
       "2196  Who would you put on a Kansas City Baseball Mo...   \n",
       "2197  Wishing you the best for the New Year and alwa...   \n",
       "\n",
       "                                        tokenized_sents  \n",
       "0     [Some, of, our, finest, plays, from, the, mont...  \n",
       "1     [It, 's, time, to, #, BringOutTheBlue, !, The,...  \n",
       "2     [@, Royals, Happy, Birthday, Ace, 30‚öæüíô, #, Tog...  \n",
       "3     [I, keep, checking, for, news, that, the, @, r...  \n",
       "4     [Welcome, home, @, Royals, !, Let, 's, keep, t...  \n",
       "...                                                 ...  \n",
       "2193  [@, Royals, #, Royals, https, :, //t.co/g6I5i7...  \n",
       "2194  [2002, #, MWL, box, score, #, 559/990, 7/1, @,...  \n",
       "2195  [Today, is, 1/1, -, just, like, this, @, KrisB...  \n",
       "2196  [Who, would, you, put, on, a, Kansas, City, Ba...  \n",
       "2197  [Wishing, you, the, best, for, the, New, Year,...  \n",
       "\n",
       "[2198 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7a6225cd97bc1bb4bb5f5ec69e69da2fee3f03c8bb8971b3b6be9e8fec8518b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
